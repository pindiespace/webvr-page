<!DOCTYPE html>
<html lang="en">
<head>
<title>Web VR Page Boilerplate</title>
<meta charset="utf-8">

<!--favicon-->
<link rel="icon" href="img/favicon.ico">

<!--set the viewport, shrink-to-fit fixes safari bug-->
<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0 shrink-to-fit=no">

<!--Web manifest.-->
<link rel="manifest" href="manifest.webmanifest">

<!--
handle iOS and android mobile
http://www.html5rocks.com/en/mobile/fullscreen/
ios fullscreen
-->
<meta name="apple-mobile-web-app-capable" content="yes">

<!--android fullscreen-->
<meta name="mobile-web-app-capable" content="yes">

<!--hide the Apple status bar-->
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

<!--default styles-->
<link rel="stylesheet" href="css/styles.css">

<!--
Detector script. Determine if polyfills needed. Couple with a loader
like head.js
-->
<script src="js/lib/feature-detector.js"></script>

<script>
  if(FeatureDetector && !FeatureDetector.canvas) {

    FeatureDetector.load([
      [
        {name: 'html5', path: 'js/lib/html5shiv.min.js', poly: true}
      ]], function () {
        console.log("added HTML5 Shiv");
        // Replace canvas tags with images.
        var c = document.getElementsByTagName('canvas');
        console.log('c.length:' + c.length)
        // Replace each canvas with a default image.
        for(var i = 0; i < c.length; i++) {
          //TODO: change so both canvas tags are replaced.
          console.log('replacing canvas tag id:' + c[i].id);
          var img = document.createElement('img');
          img.src = 'img/fallback.png';
          img.style.display = 'block';
          var parentNode = c[i].parentNode;
          parentNode.insertBefore(img, c[i]);
        }
      },
      function (percent) {
        console.log('progress function, ' + percent + '%');
        var prog = document.getElementById('webvr-page-load-progress');
        if(prog) {
          // ie8 won't write to innerHTML here.
          prog.parentNode.innerHTML = '<progress value=' + percent + '>' + percent + '%</progress>'
        }
      },
      function (err) {
        console.log('error function')
      }
    );
  }
</script>

</head>

<body>
  <header>
    <h1>WebVR - DOM Page-Friendly Boilerplate</h1>
    <nav class="menu">
      <ul>
        <li><button id="go-fullscreen">Go Fullscreen</button></li>
        <li><span>Load Progress: </span><progress id='webvr-page-load-progress' value='0' max='100'><span>0</span>%</progress></li>
      </ul>
    </nav>
  </header>
  <main>
    <section>
      <h2>Page Section</h2>
      <!--webvr sample goes here-->
      <article id="sample-webvr">
        <figure class="webvr-page">
          <canvas id='scene-cube'></canvas>
          <figcaption>Cube World</figcaption>
        </figure>
      </article>
      <!--second webvr sample goes here-->
      <article id="second-webvr">
        <figure class="webvr-page">
          <canvas id='scene-text'></canvas>
          <figcaption>3D Text World</figcaption>
        </figure>
      </article>
    </section>
  </main>
  <footer>
    <h2>Page Footer</h2>
  </footer>
<script>
  /*
   * This configures the app to use webvr-polyfill if desired, along with other params.
   */
  WebVRConfig = {
     // Forces availability of VR mode.
     FORCE_ENABLE_VR: true // Default: false. Enables VR toggles on Desktops.
     //FORCE_DISTORTION: true, // Default: false.
     // Complementary filter coefficient. 0 for accelerometer, 1 for gyro.
     //K_FILTER: 0.98, // Default: 0.98.
     // How far into the future to predict during fast motion.
     //PREDICTION_TIME_S: 0.040, // Default: 0.040 (in seconds).
     // Flag to disable touch panner. In case you have your own touch controls
     //TOUCH_PANNER_DISABLED: true, // Default: false.
     // Enable yaw panning only, disabling roll and pitch. This can be useful for
     // panoramas with nothing interesting above or below.
     //YAW_ONLY: true, // Default: false.
   };
</script>

<!--
  set up the VR scene.
-->
<script>
/*
 * Feature-detect <canvas> support and WebGL API using FeatureDetector.js.
 * The <canvas> tag can't be polyfilled for VR, and addEventListener is supported by all browsers which support <canvas>
 * More tests at: https://github.com/facebookarchive/rng.io/blob/c96a962ec18beef5f456d04820d791cbda59c2bc/dist/tests.js
*/
if(!FeatureDetector.addEventListener || !FeatureDetector.canvas) {
  //the <canvas> tags will display our error message (one reason for putting them into markup).
  //TODO: polyfill with blank GIF image.
} else {

// Setup three.js WebGL renderer. Note: Antialiasing is a big performance hit.
// Only enable it if you actually need to.
document.addEventListener('DOMContentLoaded', function() {

  /*
   * 1. Conditionally load JS Polyfills required for a VR scene.
   *  - Promise polyfill by taylorhakes
   *    https://github.com/taylorhakes/promise-polyfill
   *  - Fetch polyfill.
   *    https://github.com/github/fetch
   *  - ES5 methods (es5.js) for Object() methods.
   *    DOM methods and properties (dom.js) including querySelector(), querySelectorAll(), .classList.
   *  - Typed array polyfill (typedArray.js) for ie9 running canvas renderer.
   *    typedarray.js by inexorabletrash
   *    https://github.com/inexorabletash/polyfill
   *  - CustomEvent polyfill for IE 9, 10, 11
   *    https://github.com/krambuhl/custom-event-polyfill
   *
   * 2. Load JS Libraries.
   *  - three.js 3d library by mrdoob
   *  - CanvasRenderer for fallback from WebGL (render one frame of the VR scene to canvas).
   *  - Projector.js for Canvas rendering.
   *  - VREffect.js for stereo rendering.
   *  - VRControls.js for correct VR events.
   *    https://github.com/mrdoob/three.js/
   * 3. FeatureDetector.load() params are:
   *  - Feature name
   *  - Path to files
   *  - Whether this is a polyfill (true) or another library file (false)
   */
  FeatureDetector.load([
    [
      {name: 'addEventListener', path: 'js/lib/ie8.js', poly: true},
      {name: 'querySelectorAll', path: 'js/lib/dom.js', poly: true},
      {name: 'defineProperty', path: 'js/lib/es5.js', poly: true},
      {name: 'typedArray', path: 'js/lib/typedarray.js', poly: true},
      {name: 'promise', path: 'js/lib/Promise.min.js', poly: true}
    ],
    [
      {name: 'CustomEvent', path: 'js/lib/custom-event-polyfill.js', poly: true},
      {name: 'three', path: 'js/lib/three.min.js', poly: false}
    ],
    [
      {name: 'projector', path: 'js/lib/Projector.js', poly: false},
      {name: 'canvasRenderer', path: 'js/lib/CanvasRenderer.js', poly: false},
      {name: 'VREffect', path: 'js/lib/VREffect.js', poly: false},
      {name: 'VRControls', path: 'js/lib/VRControls.js', poly: false}
    ],
    [
      {name: 'WebVRPolyfill', path: 'js/lib/webvr-polyfill.js', poly: false}
    ],
    [
      {name: 'fetch', path: 'js/lib/fetch.js', poly: true},
      {name: 'WebVRPage', path: 'js/webvr-page.js', poly: false}
    ]
  ], function() {
    console.log('callback');

    document.getElementById('go-fullscreen').addEventListener('click', function(e) {
      manager.requestFullscreen();
    }.bind(this), false);

    // Use an existing <canvas> in the markup.
    var canvas = document.getElementById('scene-cube');
    var renderer;
    if(FeatureDetector.webGL) { // 3D scenes ok.
      renderer = new THREE.WebGLRenderer({
        antialias: true,
        canvas: canvas
      });
      renderer.setPixelRatio(window.devicePixelRatio);
    } else { // Can't do 3d, just draw the scene once and use as a fallback image.
    console.warn('no webGL, fallback to canvas still image rendering of scene');
    renderer = new THREE.CanvasRenderer({
      antialias: true,
      canvas: canvas
    });
  }

  // Canvas size determined by markup, not JS.
  var w = parseFloat(getComputedStyle(canvas).getPropertyValue('width'));
  var h = parseFloat(getComputedStyle(canvas).getPropertyValue('height'));
  var aspect = w / h;

  /*
  * 3d world example at:
  * https://github.com/jeromeetienne/threejsboilerplate/blob/master/index.html
  */

  // Create a three.js camera.
  var camera = new THREE.PerspectiveCamera(75, aspect, 0.1, 10000);

  // Apply VR headset positional data to camera.
  var controls = new THREE.VRControls(camera);

  // Apply VR stereo rendering to renderer.
  var effect = new THREE.VREffect(renderer);
  effect.setSize(w, h);

  // Create a Manager.
  window.manager = new WebVRPageManager(renderer, effect, camera, {hideButton: false, detector: (FeatureDetector || THREE.Detector)});

  // Create a three.js scene.
  var scene = new THREE.Scene();

  // Add a repeating grid as a skybox.
  var boxWidth = 5;
  var texture = THREE.ImageUtils.loadTexture(
    'img/box.png'
  );
  texture.wrapS = THREE.RepeatWrapping;
  texture.wrapT = THREE.RepeatWrapping;
  texture.repeat.set(boxWidth, boxWidth);

  var geometry = new THREE.BoxGeometry(boxWidth, boxWidth, boxWidth);
  var material = new THREE.MeshBasicMaterial({
    map: texture,
    color: 0x01BE00,
    side: THREE.BackSide
  });

  var skybox = new THREE.Mesh(geometry, material);
  window.skybox = skybox;

  // Add a separate uuid from the one THREE generates (crypto-secure).
  skybox.userData.uuid = WebVRPageManager.Util.getUUID();

  // Name it (so we could use .getObjectByName() later). Leave the generated .id alone.
  skybox.name = 'skybox';

  scene.add(skybox);

  // Create 3D objects.
  var geometry = new THREE.BoxGeometry(0.5, 0.5, 0.5);
  var material = new THREE.MeshNormalMaterial();
  var cube = new THREE.Mesh(geometry, material);

  // Add a separate uuid from the one THREE generates (crypto-secure).
  cube.userData.uuid = WebVRPageManager.Util.getUUID();

  // Name it.
  cube.name = 'spinning cube';

  // Position cube mesh
  cube.position.z = -1;

  // Add cube mesh to your three.js scene
  scene.add(cube);

  // Reset the position sensor when 'z' pressed.
  function onKey(event) {
    if (event.keyCode == 90) { // z
      controls.resetSensor();
    }
  }
  window.addEventListener('keydown', onKey, true);

  var lastRender = 0;

  // Request animation frame loop function
  function animate(timestamp) {
    // Throttle.
    var delta = Math.min(timestamp - lastRender, 500);
     lastRender = timestamp;

    // Apply rotation to cube mesh
    cube.rotation.y += delta * 0.001;

    // Update VR headset position and apply to camera.
    controls.update();

    // Render the scene through the manager.
    manager.render(scene, camera, timestamp);

    requestAnimationFrame(animate);
  }

  // Kick off animation loop, or draw a still image one time.
  if(FeatureDetector.webGL) { // Render animated 3D scene.
    animate(performance ? performance.now() : Date.now());
  } else { // Render exactly once to canvas, treat as image.
    manager.render(scene, camera);
  }

  //END OF CALLBACK FOR LOADER

}, function(percent) { // Progress function.
    console.log('progress function, ' + percent + '%');
    var prog = document.getElementById('webvr-page-load-progress');
    if(prog) {
      prog.value = percent;
      prog.getElementsByTagName('span')[0].innerHTML = percent;
    }
  }, function(s, loadCount) { // Error function.
    console.log('failed to load:' + s.src + ' count:' + loadCount);
  }); // End of Loader callback.

}); //end of DOMCOntentLoaded callback.

// Things to do once ALL content is loaded (i.e. window.onload).
window.addEventListener('load', function(e) {

});

} // End of conditional for un-polyfill-able features.

</script>
</body>
</html>
